[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nOur goals\n",
    "section": "",
    "text": "The Fish AI Consortium is a global network of individuals and organisations advancing artificial intelligence based image analysis to study fish population management, ecology, and conservation. We believe that AI has the potential to revolutionise the way we study, manage and protect fish populations in freshwater and marine ecosystems worldwide. By sharing resources, images, data and expertise, we aim to make a significant impact on the future of Earth’s aquatic ecosystems.\n\n\n\n\n\n\n\n\n\nOur goals\n\n\n\nDevelop AI-powered tools that can accurately identify fish to species, measure fish and identify individual fish from photos and videos.\nExpand the data available to fisheries managers and scientists by developing AI enhanced tools that allow image based data collection by recreational anglers, commercial fisheries, community scientists and researchers.\nMake AI resources more accessible for research and management, by developing user friendly image analyses applications and providing information and training.\nIncrease cross-disciplinary collaboration among fish biologists, fisheries researchers, computer scientists and conservation practitioners.\nApply image based AI tools to address the challenges facing fish populations, such as overfishing, habitat loss and climate change.\n\n\n\n\n\n\n\n\n1 / 3\n\n\n\n©Sebastian Pena\n\n\n\n\n2 / 3\n\n\n\n©Matthew McBrayer\n\n\n\n\n3 / 3\n\n\n\n©Milos Prelevic\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\nActivities\n\n\n\nIdentify and collaborate across the range of image based fish AI focused projects worldwide\nShare resources such as software and trained models\nShare data, including photos and videos of fish\nCreate a public bank of images and videos for AI model training\nShare experiences and skills on common challenges\nRun educational events (seminars, workshops, training courses) on image based fish AI tools\nApply for funding for joined activities and networking\nCross-test different AI models and learning resources\nDevelop user-friendly tools for broad application of AI based models\n\n\n\n\n\n\n\n\n\n\n\n\n\nWho are we\n\n\nFish AI Consortium involves a large group of people globally and is guided by a group of board members that includes world-renowned experts in the fields of artificial intelligence, fish population management, ecology and conservation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupporters\n\n2020 Pew Fellowship in Marine Conservation awarded to Asta Audzijonyte.\nCatarina Silva is supported by the Portuguese Foundation for Science and Technology - FCT - under an Individual Call to Scientific Employment Stimulus (2022.01002.CEECIND).\n\n  \n\n\n\n\n\n\n\n\n\nContact us\n\n\nIf you would like to learn more about our work or join the consortium, please contact us using the form below.\n\n\nName:  Email:  Message: \n\n           &lt;input type=\"text\" name=\"_gotcha\" tabindex=\"-1\" autocomplete=\"off\" /&gt;"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Fish AI Consortium",
    "section": "",
    "text": "NOAA Puget Sound Nearshore Fish 2017-2018 - 77,739 images sampled from video collected on and around shellfish aquaculture farms in an estuary in the Northeast Pacific; 67,990 objects (fish and crustaceans) annotated on 30,384 images.\nList of Marine/freshwater images\nBRUVNet - An open-sourced dataset from baited remote underwater video of freshwater and marine fish images used for fisheries monitoring and research\nDeep learning based Nephrops counter for demersal trawl fisheries\nFishnet Open Images Database - The v1.0.0 Fishne dataset contains 549,209 bounding boxes for 34 object classes (composed entirely of fish species and humans) on 143,818 images collected from 96 unique cameras with an average of 4 bounding boxes per image."
  },
  {
    "objectID": "resources.html#publicly-available-datasets",
    "href": "resources.html#publicly-available-datasets",
    "title": "Fish AI Consortium",
    "section": "",
    "text": "NOAA Puget Sound Nearshore Fish 2017-2018 - 77,739 images sampled from video collected on and around shellfish aquaculture farms in an estuary in the Northeast Pacific; 67,990 objects (fish and crustaceans) annotated on 30,384 images.\nList of Marine/freshwater images\nBRUVNet - An open-sourced dataset from baited remote underwater video of freshwater and marine fish images used for fisheries monitoring and research\nDeep learning based Nephrops counter for demersal trawl fisheries\nFishnet Open Images Database - The v1.0.0 Fishne dataset contains 549,209 bounding boxes for 34 object classes (composed entirely of fish species and humans) on 143,818 images collected from 96 unique cameras with an average of 4 bounding boxes per image."
  },
  {
    "objectID": "resources.html#publicly-available-models",
    "href": "resources.html#publicly-available-models",
    "title": "Fish AI Consortium",
    "section": "Publicly available models",
    "text": "Publicly available models\nMegaFishDetector v0\nGeneral purpose detector of fish shapes in images\nKakaduFishAI\nMulti-class detector for Australian fish"
  },
  {
    "objectID": "resources.html#training-resources",
    "href": "resources.html#training-resources",
    "title": "Fish AI Consortium",
    "section": "Training resources",
    "text": "Training resources\nMachine learning based image collection, annotation and classification\nIn this online course you will learn about:\n\nconcepts of data science, machine learning (ML), computer vision, deep learning and Convolutional Neural Networks (CNNs)\nhow to pre-process and pre-annotate images to accelerate your ML projects\nhow to apply data augmentation techniques\nhow to build an image classification model with your own or example data\n\nThe course uses freely available libraries and computing resources on Google Colaboratory"
  },
  {
    "objectID": "resources.html#scientific-publications",
    "href": "resources.html#scientific-publications",
    "title": "Fish AI Consortium",
    "section": "Scientific publications",
    "text": "Scientific publications\nEdge computing based real-time Nephrops (Nephrops norvegicus) catch estimation in demersal trawls using object detection models. 2024. Ercan Avsar, Jordan P. Feekings, Ludvig Ahm Krag . Scientific Reports\nHerbivorous fish feeding dynamics and energy expenditure on a coral reef: Insights from stereo-video and AI-driven 3D tracking. 2024. Julian Lilkendey, Cyril Barrelet, Jingjing Zhang, Michael Meares, Houssam Larbi, Gérard Subsol, Marc Chaumont, Armagan Sabetian. Ecology and Evolution\n\nThe publication details an advanced methodological framework for fish detection, identification, and 3D tracking. Utilizing YOLOv5 for object detection, iNaturalist data for species identification, and DeepSORT for multi-object tracking, it describes and presents code for precise classification and tracking from stereo-video. Additionally, it includes code for data optimization and calculating rates of energy expenditure from fish movement. This integration of AI with conventional field methods enhances our understanding of energy dynamics in aquatic ecosystems.\n\nA Scalable Open-Source Framework for Machine Learning-Based Image Collection, Annotation and Classification: A Case Study for Automatic Fish Species Identification. 2022 Catarina NS Silva, Justas Dainys, Sean Simmons, Vincentas Vienožinskis, Asta Audzijonyte. Sustainability 14 (21), 14324.\nPreprint: A machine learning based image classification method to estimate fish sizes from images without a specified reference object. 2022. Catarina Nunes Soares Silva, Justas Dainys, Sean Simmons, Asta Audzijonyte. bioRxiv\nEstimating catch rates in real time: Development of a deep learning based Nephrops (Nephrops norvegicus) counter for demersal trawl fisheries. 2023. Ercan Avsar, Jordan P. Feekings, Ludvig Ahm Krag. Frontiers in Marine Science\nConserve the open media ecosystem! Legal and ethical considerations when using online repositories for AI training in ecological research. 2023. Julian Lilkendey. Ecology Letters\n\nThis publication contributes to the discussion on the responsible use of media from online repositories for AI training. It offers best practices along the FAIR principles to help researchers use these resources ethically and legally. Particularly valuable is the comprehensive overview of Creative Commons (CC) licences and their implications for the use of CC licensed media in AI training, enabling researchers to understand and comply with the nuanced requirements of different licence types."
  },
  {
    "objectID": "resources.html#media-and-other-popular-science",
    "href": "resources.html#media-and-other-popular-science",
    "title": "Fish AI Consortium",
    "section": "Media and other popular science",
    "text": "Media and other popular science\nStory about the collaboration between Microsoft and Australian Government’s Supervising Scientist Branch to build the baited remote underwter video image dataset from images at the Kakadu National park - Citizen scientists, AI and cloud bond to boost billabong health in the Top End"
  },
  {
    "objectID": "meetings_seminars.html",
    "href": "meetings_seminars.html",
    "title": "Fish AI Consortium",
    "section": "",
    "text": "In our monthly online seminar series we aim to show our achievements, brainstorm, share challenges and foster collaborations.\nThese seminars will be recorded and available online.\n\n\n\nOctober 30, 2024\nPresenter: Julian Lilkendey, Leibniz Centre for Tropical Marine Research\nAI-driven species recognition and tracking is advancing at breakneck speed. However, we are still lacking good training data for data-poor tropical regions and reliable location-invariant realtime 3D tracking methodologies. In my talk, I will focus on leveraging stereo-video to capture 3D fish trajectories, followed by AI-driven multi-object tracking to decode fish energy expenditure and behaviour. Specifically, we employed DeepSORT to track multiple fish in complex coral reef environments. To overcome training data scarcity, we integrated iNaturalist media, which provided diverse, real-world examples. During this process, I established best practices for incorporating community-science media into AI training, ensuring data quality and ethical use. This fusion of stereo-video, AI, and the use of photos identified by community experts enables precise and reliable calculation of metrics like field metabolic rates, and eventually the development of novel ethodiversity scores. These advancements contribute to the derivation of Energy Seascapes - models highlighting the energetic burden to life in certain habitats.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 4, 2024\nPresenter: Filippo Varini, Imperial College London\nWe present a computer vision pipeline that accurately processes underwater videos of sharks and rays of any species and location. We share how this pipeline can be reproduced to train new underwater fish classifiers faster.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJune 18, 2024\nPresenters: Brooke Gibbons and Tim Langlois, Global Archive\nBrooke and Tim will be talking about their work with Global Archive to provide a portal for the discovery and sharing of stereo-video image annotation data of both marine fish and habitats.\nThey will present a set of open-access workflows and web app to help with the QAQC of fish biogeographic, abundance and length data and give examples of how this has benefited recent continental synthesis and national environmental reporting around Australia.\nSome pre-reading for the seminar: Stereo-video workflows for fish and benthic ecologists\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2024\nPresenter: Tom Wye, Fishial\nOver the last three years the not for profit, Fishial.AI project has been developing a photo image content management system to assist in annotating fish species images and building a species segmentation and classification AI model in the recreational fish species space for anglers and divers. The model can currently identify 294 fish species.\n\n\n\n\n\n\n\n\nSlides:\n Overview of the Fishial project\nFish species identification model\n\n\n\n\nMarch 21, 2024\nPresenter: Professor Rod Connolly, FishID (Director)\nThe application of automation using underwater computer vision is revolutionising fisheries science. Our use of automated data extraction on robust and inexpensive camera systems is providing a step-change in efficiency for monitoring fish. Working collaboratively with fisheries managers and conservation NGOs, we demonstrate how automation overcomes barriers to reliable monitoring in situations that until now have been difficult, dangerous, or prohibitively expensive. We highlight examples of stock assessments for benthic fisheries and surveys of fish abundance and size on restored habitats as a basis for environmental accounting.\n\n\n\n\n\nFishID automated identification and counting of fish on restored shellfish reef"
  },
  {
    "objectID": "meetings_seminars.html#online-seminars",
    "href": "meetings_seminars.html#online-seminars",
    "title": "Fish AI Consortium",
    "section": "",
    "text": "In our monthly online seminar series we aim to show our achievements, brainstorm, share challenges and foster collaborations.\nThese seminars will be recorded and available online.\n\n\n\nOctober 30, 2024\nPresenter: Julian Lilkendey, Leibniz Centre for Tropical Marine Research\nAI-driven species recognition and tracking is advancing at breakneck speed. However, we are still lacking good training data for data-poor tropical regions and reliable location-invariant realtime 3D tracking methodologies. In my talk, I will focus on leveraging stereo-video to capture 3D fish trajectories, followed by AI-driven multi-object tracking to decode fish energy expenditure and behaviour. Specifically, we employed DeepSORT to track multiple fish in complex coral reef environments. To overcome training data scarcity, we integrated iNaturalist media, which provided diverse, real-world examples. During this process, I established best practices for incorporating community-science media into AI training, ensuring data quality and ethical use. This fusion of stereo-video, AI, and the use of photos identified by community experts enables precise and reliable calculation of metrics like field metabolic rates, and eventually the development of novel ethodiversity scores. These advancements contribute to the derivation of Energy Seascapes - models highlighting the energetic burden to life in certain habitats.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOctober 4, 2024\nPresenter: Filippo Varini, Imperial College London\nWe present a computer vision pipeline that accurately processes underwater videos of sharks and rays of any species and location. We share how this pipeline can be reproduced to train new underwater fish classifiers faster.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJune 18, 2024\nPresenters: Brooke Gibbons and Tim Langlois, Global Archive\nBrooke and Tim will be talking about their work with Global Archive to provide a portal for the discovery and sharing of stereo-video image annotation data of both marine fish and habitats.\nThey will present a set of open-access workflows and web app to help with the QAQC of fish biogeographic, abundance and length data and give examples of how this has benefited recent continental synthesis and national environmental reporting around Australia.\nSome pre-reading for the seminar: Stereo-video workflows for fish and benthic ecologists\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2024\nPresenter: Tom Wye, Fishial\nOver the last three years the not for profit, Fishial.AI project has been developing a photo image content management system to assist in annotating fish species images and building a species segmentation and classification AI model in the recreational fish species space for anglers and divers. The model can currently identify 294 fish species.\n\n\n\n\n\n\n\n\nSlides:\n Overview of the Fishial project\nFish species identification model\n\n\n\n\nMarch 21, 2024\nPresenter: Professor Rod Connolly, FishID (Director)\nThe application of automation using underwater computer vision is revolutionising fisheries science. Our use of automated data extraction on robust and inexpensive camera systems is providing a step-change in efficiency for monitoring fish. Working collaboratively with fisheries managers and conservation NGOs, we demonstrate how automation overcomes barriers to reliable monitoring in situations that until now have been difficult, dangerous, or prohibitively expensive. We highlight examples of stock assessments for benthic fisheries and surveys of fish abundance and size on restored habitats as a basis for environmental accounting.\n\n\n\n\n\nFishID automated identification and counting of fish on restored shellfish reef"
  },
  {
    "objectID": "meetings_seminars.html#first-meeting",
    "href": "meetings_seminars.html#first-meeting",
    "title": "Fish AI Consortium",
    "section": "First meeting",
    "text": "First meeting\nThe first online consortium meeting was held on June 30 (Friday) 2023 at 8am (East Australian time).\nWe discussed the main priorities and ideas for the consortium and had brief presentations from some consortium members about their work and interest, including:\n\nAndrew Jansen (Australian Government’s Supervising Scientist Branch): BRUVNet dataset and models for fish ID\nDan Morris (Google): lessons from related domains and suggestions for the consortium\nNathaniel “Than” Hitt (US Geological Survey): Individual fish identification models\nCatarina Silva (University of Coimbra, Portugal): Models for fish size classification from citizen science and social media photos\n\nWe also had a brief discussion on introducing specific goals and key priorities (building an image bank, testing models, combining models, expert fish identification in images, funding application) and people willing to help with them or lead them. Next meetings could be specifically targeted to just one of these goals b) computing resources that consortium could use. Is there any cloud computing available, can we apply for it? c) please provide materials (links, publications, your photo, your description, etc) for the website and let us know if you would like to help with building it. We have a dedicated domain which will soon replace the GitHub link. d) how to reach groups in Asia, Africa and South America? e) other topics"
  },
  {
    "objectID": "our_team.html#board-members",
    "href": "our_team.html#board-members",
    "title": "Fish AI Consortium",
    "section": "Board members",
    "text": "Board members\n\n\n\n\n\n\n\n\n\n Amanda Barney  Teem Fish Monitoring, Canada\n\n\n Teem Fish Monitoring is a fisheries electronic monitoring technology company dedicated to bringing the best automation tools and efficiencies to our data collection and analysis processes\n\n\n\n\n\n\n\n\n\n\n\n Andrew J Jansen  Department of Climate Change, Energy, Environment and Water, Australia\n\n\n Focusing at the intersection of deep learning and ecology to develop wildlife monitoring solutions using a range of remote sensing technologies (e.g. drones, underwater cameras, multi-spectral sensors, IoT Edge, cloud computing)\n\n\n\n\n\n\n\n\n\n\n\n Asta Audzijonyte\n(co-founder)  University of Tasmania, Australia & Nature Research Centre, Lithuania\n\n\n ML models for citizen science and social media data, especially models for fish size determination\n\n\n\n\n\n\n\n\n\n\n\n Catarina Silva\n(co-founder)  University of Coimbra, Portugal\n\n\n ML models for automatic identification of species and sizes from images; multidisciplinary and innovative methods to fisheries research; marine population dynamics\n\n\n\n\n\n\n\n\n\n\n\n Kieran Hyder  CEFAS, UK\n\n\n Application of science to support policy and management of fisheries focusing on the social, economic, and biological impacts of marine recreational fisheries; novel approaches to support fisheries monitoring, modelling, assessment and management\n\n\n\n\n\n\n\n\n\n\n\n Kim Friedman  FAO, Italy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Lisa Kellogg  Virginia Institute of Marine Science, USA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Luyen Chou  GotOne fishing app, USA\n\n\n GotOne is a fishing log app that empowers recreational anglers with the data they need to catch more fish and conserve our fisheries\n\n\n\n\n\n\n\n\n\n\n\n Nathaniel “Than” Hitt  West Virginia Rivers Coalition, USA\n\n\n Freshwater biologist with expertise in fisheries, water quality, climate change, and open-science strategies\n\n\n\n\n\n\n\n\n\n\n\n Steve Munch  University of California, Santa Cruz, USA\n\n\n I use nonlinear dynamics, optimal control, and machine learning to develop data-driven tools for ecosystem management\n\n\n\n\n\n\n\n\n\n\n\n Tom Wye  Fishial.AI, USA"
  },
  {
    "objectID": "our_team.html#general-members",
    "href": "our_team.html#general-members",
    "title": "Fish AI Consortium",
    "section": "General members",
    "text": "General members\n\n\n\n\n\n\n\n\n\n Alexander Dungate  OnDeck Fisheries AI Inc.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Alyssa Marshell  University of Tasmania, Australia\n\n\n AI for automatic identification of fish species and sizes from video and images; automate annual monitoring of fisheries species; increase length data available for length-based annual stock assessments\n\n\n\n\n\n\n\n\n\n\n\n Barbara Block  Stanford University, USA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Ben Letcher  U.S. Geological Survey, USA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Christian Skov  National Institute of Aquatic Resources, Denmark\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dan Morris  Google AI for Nature and Society, USA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Eelke Folmer  Aeria\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Ercan Avsar  Technical University of Denmark, Denmark\n\n\n Underwater video processing for automatic species recognition; edge computing and real-time object detection with deep learning models\n\n\n\n\n\n\n\n\n\n\n\n Iñaki Quincoces  AZTI, Spain\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Jimmy Freese  Ai.Fish, USA\n\n\n Ai.Fish is a Computer Vision and Artificial Intelligence company with significant ongoing R&D in data science, deep learning, convolutional neural networks and object detection and tracking to address problems in marine sustainability and conservation.\n\n\n\n\n\n\n\n\n\n\n\n Jordan Lynch  Virginia Institute of Marine Science, USA\n\n\n My interests lie in improving shellfish aquaculture production, quality, profitability, and environmental sustainability through applied research and workforce development.\n\n\n\n\n\n\n\n\n\n\n\n Julian Lilkendey  Auckland University of Technology, New Zealand\n\n\n Harnessing AI to identify, track, and analyse the movements of fish, my research delves into their energetic and behavioural adaptations to challenging marine environments.\n\n\n\n\n\n\n\n\n\n\n\n Justas Dainys  Nature Research Centre, Lithuania\n\n\n My main research interests are related to the study of eel population status, biological indicators and spawning migrations using telemetry methods, as well as the application of novel and innovative methods for assessing the impact of recreational fishing on fish populations.\n\n\n\n\n\n\n\n\n\n\n\n Justin Chan  OnDeck Fisheries AI Inc.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Mark Sudul  Archipelago\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Michaela Holubová  Biology Centre CAS, Czech Republic\n\n\n Main focus of my interest is the behavioral ecology of freshwater fish via a non-invasive approach involving UVC.\n\n\n\n\n\n\n\n\n\n\n\n Noel Clark  Colorado State University, USA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Osamu Kishida  Hokkaido University, Japan\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Paul Clerkin  Virginia Institute of Marine Science, USA\n\n\n I am a taxonomist exploring innovative ways to enhance identification tools and develop AI solutions to improve the accuracy of species identification and data collection for deep-sea sharks\n\n\n\n\n\n\n\n\n\n\n\n Raiana McKinney  The Pew Charitable Trusts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Rod Connolly  Griffith University\n\n\n I am the Director of FishID and the Global Wetlands Project. We develop AI tools and coordinated monitoring systems for aquatic ecosystems.\n\n\n\n\n\n\n\n\n\n\n\nSean Simmons  Angler’s Atlas, Canada\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSebastian Lopez-Marcano  Griffith University\n\n\n I am a data scientist developing AI solutions for AgTech, conservation and education.\n\n\n\n\n\n\n\n\n\n\n\nSebastian Uhlmann  Dr Snapper, Flanders Research Institute for Agriculture, Fisheries and Food (ILVO), Vrije Universiteit Brussels (VUB)\n\n\n I am a fisheries biologist with an interest in bycatch, discards, fish welfare, post-release survival and hook-less fishing by means of underwater camera only.\n\n\n\n\n\n\n\n\n\n\n\nSophie Pitois  CEFAS, UK\n\n\n I’m a Zooplankton ecologist focussing on optimizing imaging tools for automated monitoring; in particular the use of AI methods for real-time data collection and visualisation\n\n\n\n\n\n\n\n\n\n\n\n Thor Veen  Aeria\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Tim Sartwell  NOAA Fisheries\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Victor Anton  Wildlife.ai, New Zealand\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Yoichiro Kanno  Colorado State University, USA\n\n\n I am a stream fish ecologist working on projects in USA and Japan"
  }
]